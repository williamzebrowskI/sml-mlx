{
  "vocab_size": 28000,
  "num_transformer_layers": 6,
  "model_dim": 512,
  "num_heads": 8,
  "head_dim": 64,

  "ffn_multipliers": [3,3,3,3,3,3],
  "ffn_dim_divisor": 256,
  "ffn_with_glu": true,

  "rope_freq_constant": 10000,
  "rope_max_length": 4096,
  "normalization_layer_name": "rmsnorm",
  "activation_fn_name": "silu",

  "context_size": 512,
  "dropout": 0.0,

  "max_iterations": 1000000,
  "warmup_iterations": 20000,
  "max_lr": 0.0001,
  "min_lr": 0.000001,
  "weight_decay": 0.01,
  "grad_clip": 1.0,

  "mlx_dtype": "bfloat16",
  "tokenizer_path": "tokenizer/fineweb_spm/spm.model",
  "checkpoint_dir": "runs/sml-lm",
  "use_fast_sdp": false,
  "local_bs": 2,
  "accum_steps": 8
}